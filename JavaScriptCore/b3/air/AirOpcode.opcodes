# Copyright (C) 2015 Apple Inc. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS''
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
# THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
# BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
# THE POSSIBILITY OF SUCH DAMAGE.

# Syllabus:
#
# Roles and types:
# U:G => use of a general-purpose register or value
# D:G => def of a general-purpose register or value
# UD:G => use and def of a general-purpose register or value
# UA:G => UseAddr (see comment in Arg.h)
# U:F => use of a float register or value
# D:F => def of a float register or value
# UD:F => use and def of a float register or value
#
# Argument kinds:
# Tmp => temporary or register
# Imm => 32-bit immediate int
# Imm64 => TrustedImm64
# Addr => address as temporary/register+offset
# Index => BaseIndex address
# Abs => AbsoluteAddress
#
# The parser views these things as keywords, and understands that they fall into two distinct classes
# of things. So, although this file uses a particular indentation style, none of the whitespace or
# even newlines are meaningful to the parser. For example, you could write:
#
# Foo42 U:G, UD:F Imm, Tmp Addr, Tmp
#
# And the parser would know that this is the same as:
#
# Foo42 U:G, UD:F
#     Imm, Tmp
#     Addr, Tmp
#
# I.e. a two-form instruction that uses a GPR or an int immediate and uses+defs a float register.

# Note that the opcodes here have a leading capital (Add32) but must correspond to MacroAssembler
# API that has a leading lower-case (add32).

Nop

Add32 U:G, UD:G
    Tmp, Tmp
    Imm, Addr
    Imm, Tmp
    Addr, Tmp
    Tmp, Addr

Add32 U:G, U:G, D:G
    Imm, Tmp, Tmp

Add64 U:G, UD:G
    Tmp, Tmp
    Imm, Addr
    Imm, Tmp
    Addr, Tmp

Add64 U:G, U:G, D:G
    Imm, Tmp, Tmp

AddDouble U:F, UD:F
    Tmp, Tmp
    Addr, Tmp

Sub32 U:G, UD:G
    Tmp, Tmp
    Imm, Addr
    Imm, Tmp
    Addr, Tmp
    Tmp, Addr

Sub64 U:G, UD:G
    Tmp, Tmp
    Imm, Tmp

SubDouble U:F, UD:F
    Tmp, Tmp
    Addr, Tmp

Neg32 UD:G
    Tmp
    Addr

Neg64 UD:G
    Tmp

Mul32 U:G, UD:G
    Tmp, Tmp
    Addr, Tmp

Mul32 U:G, U:G, D:G
    Imm, Tmp, Tmp

Mul64 U:G, UD:G
    Tmp, Tmp

MulDouble U:F, UD:F
    Tmp, Tmp
    Addr, Tmp

DivDouble U:F, UD:F
    Tmp, Tmp
    Addr, Tmp

X86ConvertToDoubleWord32 U:G, D:G
    Tmp*, Tmp*

X86ConvertToQuadWord64 U:G, D:G
    Tmp*, Tmp*

X86Div32 UD:G, UD:G, U:G
    Tmp*, Tmp*, Tmp

X86Div64 UD:G, UD:G, U:G
    Tmp*, Tmp*, Tmp

Lea UA:G, D:G
    Addr, Tmp

And32 U:G, UD:G
    Tmp, Tmp
    Imm, Tmp
    Tmp, Addr
    Addr, Tmp
    Imm, Addr

And64 U:G, UD:G
    Tmp, Tmp
    Imm, Tmp

Lshift32 U:G, UD:G
    Tmp*, Tmp
    Imm, Tmp

Lshift64 U:G, UD:G
    Tmp*, Tmp
    Imm, Tmp

Rshift32 U:G, UD:G
    Tmp*, Tmp
    Imm, Tmp

Rshift64 U:G, UD:G
    Tmp*, Tmp
    Imm, Tmp

Urshift32 U:G, UD:G
    Tmp*, Tmp
    Imm, Tmp

Urshift64 U:G, UD:G
    Tmp*, Tmp
    Imm, Tmp

Or32 U:G, UD:G
    Tmp, Tmp
    Imm, Tmp
    Tmp, Addr
    Addr, Tmp
    Imm, Addr

Or64 U:G, UD:G
    Tmp, Tmp
    Imm, Tmp

Xor32 U:G, UD:G
    Tmp, Tmp
    Imm, Tmp
    Tmp, Addr
    Addr, Tmp
    Imm, Addr

Xor64 U:G, UD:G
    Tmp, Tmp
    Tmp, Addr
    Imm, Tmp

Not32 UD:G
    Tmp
    Addr

Not64 UD:G
    Tmp
    Addr

ConvertInt32ToDouble U:G, D:F
    Tmp, Tmp
    Addr, Tmp

ConvertInt64ToDouble U:G, D:F
    Tmp, Tmp

# Note that Move operates over the full register size, which is either 32-bit or 64-bit depending on
# the platform. I'm not entirely sure that this is a good thing; it might be better to just have a
# Move64 instruction. OTOH, our MacroAssemblers already have this notion of "move()" that basically
# means movePtr.
Move U:G, D:G
    Tmp, Tmp
    Imm, Tmp as signExtend32ToPtr
    Imm64, Tmp
    Addr, Tmp as loadPtr # This means that "Move Addr, Tmp" is code-generated as "load" not "move".
    Index, Tmp as loadPtr
    Tmp, Addr as storePtr
    Tmp, Index as storePtr
    Imm, Addr as storePtr

Move32 U:G, D:G
    Tmp, Tmp as zeroExtend32ToPtr
    Addr, Tmp as load32
    Index, Tmp as load32
    Tmp, Addr as store32
    Tmp, Index as store32
    Imm, Addr as store32
    Imm, Index as store32

SignExtend32ToPtr U:G, D:G
    Tmp, Tmp

MoveDouble U:F, D:F
    Tmp, Tmp
    Addr, Tmp as loadDouble
    Index, Tmp as loadDouble
    Tmp, Addr as storeDouble
    Tmp, Index as storeDouble

MoveZeroToDouble D:F
    Tmp

Move64ToDouble U:G, D:F
    Tmp, Tmp
    Addr, Tmp as loadDouble

MoveDoubleTo64 U:F, D:G
    Tmp, Tmp
    Addr, Tmp as load64

Load8 U:G, D:G
    Addr, Tmp
    Index, Tmp

Load8SignedExtendTo32 U:G, D:G
    Addr, Tmp
    Index, Tmp

Load16 U:G, D:G
    Addr, Tmp
    Index, Tmp

Load16SignedExtendTo32 U:G, D:G
    Addr, Tmp
    Index, Tmp

Compare32 U:G, U:G, U:G, D:G
    RelCond, Tmp, Tmp, Tmp
    RelCond, Tmp, Imm, Tmp

Compare64 U:G, U:G, U:G, D:G
    RelCond, Tmp, Imm, Tmp
    RelCond, Tmp, Tmp, Tmp

Test32 U:G, U:G, U:G, D:G
    ResCond, Addr, Imm, Tmp
    ResCond, Tmp, Tmp, Tmp

Test64 U:G, U:G, U:G, D:G
    ResCond, Tmp, Imm, Tmp
    ResCond, Tmp, Tmp, Tmp

# Note that branches have some logic in AirOptimizeBlockOrder.cpp. If you add new branches, please make sure
# you opt them into the block order optimizations.

Branch8 U:G, U:G, U:G /branch
    RelCond, Addr, Imm
    RelCond, Index, Imm

Branch32 U:G, U:G, U:G /branch
    RelCond, Addr, Imm
    RelCond, Tmp, Tmp
    RelCond, Tmp, Imm
    RelCond, Tmp, Addr
    RelCond, Addr, Tmp
    RelCond, Index, Imm

Branch64 U:G, U:G, U:G /branch
    RelCond, Tmp, Tmp
    RelCond, Tmp, Addr
    RelCond, Addr, Tmp
    RelCond, Index, Tmp

BranchTest8 U:G, U:G, U:G /branch
    ResCond, Addr, Imm
    ResCond, Index, Imm

BranchTest32 U:G, U:G, U:G /branch
    ResCond, Tmp, Tmp
    ResCond, Tmp, Imm
    ResCond, Addr, Imm
    ResCond, Index, Imm

# Warning: forms that take an immediate will sign-extend their immediate. You probably want
# BranchTest32 in most cases where you use an immediate.
BranchTest64 U:G, U:G, U:G /branch
    ResCond, Tmp, Tmp
    ResCond, Tmp, Imm
    ResCond, Addr, Imm
    ResCond, Addr, Tmp
    ResCond, Index, Imm

BranchDouble U:G, U:F, U:F /branch
    DoubleCond, Tmp, Tmp

BranchAdd32 U:G, U:G, UD:G /branch
    ResCond, Tmp, Tmp
    ResCond, Imm, Tmp
    ResCond, Imm, Addr
    ResCond, Tmp, Addr
    ResCond, Addr, Tmp

BranchAdd64 U:G, U:G, UD:G /branch
    ResCond, Imm, Tmp
    ResCond, Tmp, Tmp

BranchMul32 U:G, U:G, UD:G /branch
    ResCond, Tmp, Tmp
    ResCond, Addr, Tmp

BranchMul64 U:G, U:G, UD:G /branch
    ResCond, Tmp, Tmp

BranchSub32 U:G, U:G, UD:G /branch
    ResCond, Tmp, Tmp
    ResCond, Imm, Tmp
    ResCond, Imm, Addr
    ResCond, Tmp, Addr
    ResCond, Addr, Tmp

BranchSub64 U:G, U:G, UD:G /branch
    ResCond, Imm, Tmp
    ResCond, Tmp, Tmp

BranchNeg32 U:G, UD:G /branch
    ResCond, Tmp

BranchNeg64 U:G, UD:G /branch
    ResCond, Tmp

MoveConditionally32 U:G, U:G, U:G, U:G, UD:G
    RelCond, Tmp, Tmp, Tmp, Tmp

MoveConditionally64 U:G, U:G, U:G, U:G, UD:G
    RelCond, Tmp, Tmp, Tmp, Tmp

MoveConditionallyTest32 U:G, U:G, U:G, U:G, UD:G
    ResCond, Tmp, Tmp, Tmp, Tmp
    ResCond, Tmp, Imm, Tmp, Tmp

MoveConditionallyTest64 U:G, U:G, U:G, U:G, UD:G
    ResCond, Tmp, Tmp, Tmp, Tmp
    ResCond, Tmp, Imm, Tmp, Tmp

MoveConditionallyDouble U:G, U:F, U:F, U:G, UD:G
    DoubleCond, Tmp, Tmp, Tmp, Tmp

MoveDoubleConditionally32 U:G, U:G, U:G, U:F, UD:F
    RelCond, Tmp, Tmp, Tmp, Tmp

MoveDoubleConditionally64 U:G, U:G, U:G, U:F, UD:F
    RelCond, Tmp, Tmp, Tmp, Tmp

MoveDoubleConditionallyTest32 U:G, U:G, U:G, U:F, UD:F
    ResCond, Tmp, Tmp, Tmp, Tmp
    ResCond, Tmp, Imm, Tmp, Tmp

MoveDoubleConditionallyTest64 U:G, U:G, U:G, U:F, UD:F
    ResCond, Tmp, Tmp, Tmp, Tmp
    ResCond, Tmp, Imm, Tmp, Tmp

MoveDoubleConditionallyDouble U:G, U:F, U:F, U:F, UD:F
    DoubleCond, Tmp, Tmp, Tmp, Tmp

Jump /branch

Ret /terminal

Oops /terminal

# Air allows for exotic behavior. A Patch's behavior is determined entirely by the Special operand,
# which must be the first operand.
special Patch

